#-----å¯¼å…¥åº“
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd 
import seaborn as sns
from sklearn import metrics
from pandas import read_csv
from matplotlib import pyplot
from sqlalchemy import values

from numpy import asarray, quantile
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.ensemble import RandomForestRegressor


#-----å¯¼å…¥æ•°æ®
series = series = read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv', header = 0, index_col = 0)
print(series)
values = series.values

#-----å¯è§†åŒ–æ•°æ®
pyplot.plot(values)
pyplot.show()

#-----é¢„æµ‹
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    n_vars = 1 if type(data) is list else  data.shape[1]
    df = DataFrame(data)
    cols = list()

    for i in range(n_in,0,-1):
        cols.append(df.shift(i))

    for i in range(0,n_out):
        cols.append(df.shift(-i))
    
    agg = concat(cols,axis=1)

    if dropnan:
        agg.dropna(inplace=True)

    return agg.values

#-----å‡†å¤‡æ•°æ®é›†
series = read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-max-temperatures.csv', header=0, index_col=0)
data = series.values
n_test = 100 #æ¨¡å‹æµ‹è¯•çš„æ•°é‡æ˜¯100ä¸ª

def train_test_split(data,n_test): #æŠŠæ‰€æœ‰æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    return data[:-n_test,:],data[-n_test:,:]

train,test = train_test_split(data,n_test) # train_test_splitï¼ˆï¼‰å‡½æ•°å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†trainå’Œæµ‹è¯•é›†testï¼Œæ•°æ®åº“ä¸ºdataï¼Œéšæœºæ•°é‡ä¸º100

#--è®­ç»ƒé›†
Train = series_to_supervised(train,n_in = 6) #å°†æ—¶é—´æ•°æ®é›†è½¬æ¢ä¸ºç”¨äºå­¦ä¹ è®­ç»ƒçš„æ•°æ®é›†,ä»ä¸Šé¢ğŸ‘†åˆ’åˆ†å‡ºæ¥çš„trainä¸­é€‰60%
X_train,y_train = Train[:,:-1],Train[:,-1] # X:è¦åˆ’åˆ†çš„æ ·æœ¬ç‰¹å¾é›†ï¼ˆè¾“å…¥çš„ä¿¡æ¯ï¼‰ y:éœ€è¦åˆ’åˆ†çš„æ ·æœ¬ç»“æœï¼ˆè¾“å‡ºç»“æœï¼‰
print("--Train-- :",Train)
#--æµ‹è¯•é›†
Test = series_to_supervised(train,n_in = 6)
X_test,y_test = Train[:,:-1],Train[:,-1]
print("--Test--: ",Test)

#-----å»ºç«‹å›å½’æ¨¡å‹ï¼Œä½¿ç”¨è®­ç»ƒé›†train
model = RandomForestRegressor(n_estimators = 1000) #n_estimatorsï¼šå†³ç­–æ ‘çš„ä¸ªæ•°ï¼Œè¶Šå¤šè¶Šå¥½ï¼Œä½†æ˜¯æ€§èƒ½å°±ä¼šè¶Šå·®
model.fit(X_train,y_train)

#-----é¢„æµ‹
row = values[-6:].flatten() # ä¸Šé¢n_inæ˜¯6ï¼Œæ‰€ä»¥å€’åºæ’åˆ—ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ ä¸º-6ï¼Œjå€¼ç¼ºçœé»˜è®¤æ˜¯0ï¼Œ
                            # å…·ä½“è§https://blog.csdn.net/qiushangren/article/details/103550923?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-4-103550923-null-null.pc_agg_new_rank&utm_term=Pythonä¸­values%E3%80%94%3A%2C0%E3%80%95ä»€ä¹ˆæ„æ€&spm=1000.2123.3001.4430 ,
                            # åœ¨æœ«å°¾åŠ ä¸€ä¸ªflatten() å˜æˆä¸€è¡Œçš„æ–¹ä¾¿ç»Ÿè®¡åˆ†æ,é»˜è®¤ç¼ºçœå‚æ•°ä¸º0ï¼Œä¹Ÿå°±æ˜¯è¯´flatten()å’Œflatte(0)æ•ˆæœä¸€æ ·ã€‚
yhat = model.predict(asarray([row]))
print('Input: %s, Predicted: %.3f' % (row, yhat[0]))

#-----æ¢¯åº¦æå‡å›å½’
#https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html

from sklearn.ensemble import GradientBoostingRegressor
quantile = [0.01,0.05,0.50,0.95,0.99] # å››åˆ†ä½æ•°

#-----æ¢¯åº¦æå‡å›å½’å‡½æ•°
def GBM(q): # å…³äºGBRå‡½æ•°ï¼Œè§https://blog.csdn.net/anshiquanshu/article/details/78542852 
    modele = GradientBoostingRegressor(loss='quantile',# lossæŒ‡çš„æ˜¯æ¯ä¸€æ¬¡èŠ‚ç‚¹åˆ†è£‚æ‰€è¦æœ€å°åŒ–çš„æŸå¤±å‡½æ•°
                                        alpha=q, # æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­åˆé€‚çš„å­¦ä¹ ç‡ï¼Œæ›´åˆé€‚çš„å«æ³•â€œæ­¥é•¿â€ï¼Œæ­¥é•¿å†³å®šäº†æ¯ä¸€æ¬¡è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œä¼šå¾€æ¢¯åº¦ä¸‹é™çš„æ–¹å‘ç§»åŠ¨çš„è·ç¦»ï¼Œ
                                                    #å¦‚æœæ­¥é•¿å¾ˆå¤§ï¼Œç®—æ³•ä¼šåœ¨å±€éƒ¨æœ€ä¼˜ç‚¹æ¥å›è·³è·ƒï¼Œä¸ä¼šæ”¶æ•›ï¼Œå¦‚æœæ­¥é•¿å¾ˆå°ï¼Œç®—æ³•æ”¶æ•›é€Ÿåº¦å¾ˆæ…¢ https://www.zhihu.com/question/54097634?sort=created
                                        n_estimators=500, # å®šä¹‰äº†éœ€è¦ä½¿ç”¨åˆ°çš„å†³å®šæ ‘çš„æ•°é‡
                                        max_depth=8,# max_depthå®šä¹‰äº†æ ‘çš„æœ€å¤§æ·±åº¦
                                        learning_rate=.01, # å†³å®šç€æ¯ä¸€ä¸ªå†³å®šæ ‘å¯¹äºæœ€ç»ˆç»“æœçš„å½±å“ã€‚GBMè®¾å®šäº†åˆå§‹çš„æƒé‡å€¼ä¹‹åï¼Œæ¯ä¸€æ¬¡æ ‘åˆ†ç±»éƒ½ä¼šæ›´æ–°è¿™ä¸ªå€¼ï¼Œ
                                                             #è€Œlearning_ rateæ§åˆ¶ç€æ¯æ¬¡æ›´æ–°çš„å¹…åº¦ã€‚ä¸€èˆ¬æ¥è¯´è¿™ä¸ªå€¼ä¸åº”è¯¥è®¾çš„æ¯”è¾ƒå¤§ï¼Œå› ä¸ºè¾ƒå°çš„learning rateä½¿å¾—æ¨¡å‹å¯¹ä¸åŒçš„æ ‘æ›´åŠ ç¨³å¥ï¼Œå°±èƒ½æ›´å¥½åœ°ç»¼åˆå®ƒä»¬çš„ç»“æœã€‚
                                        min_samples_leaf=20, # min_samples_leaf å®šä¹‰äº†æ ‘ä¸­ä¸€ä¸ªèŠ‚ç‚¹æ‰€éœ€è¦ç”¨æ¥åˆ†è£‚çš„æœ€å°‘æ ·æœ¬æ•°
                                        min_samples_split=20) # min_samples_split å®šä¹‰äº†æ ‘ä¸­ç»ˆç‚¹èŠ‚ç‚¹æ‰€éœ€è¦çš„æœ€å°‘çš„æ ·æœ¬æ•° 

    modele.fit (X_train,y_train) # X_train,y_trainå°†å¡«å……æ¨¡å‹
    predict = pd.Series(modele.predict(X_test).round(2)) # roundå–å°æ•°ç‚¹å2ä½

    return predict,modele           